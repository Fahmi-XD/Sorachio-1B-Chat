{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1utsA0r3bGu1-yv9o0rSATI4Kr89ENqXa","authorship_tag":"ABX9TyPBZiHZDxmYYMIBZtKuB4U5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9c157f33","executionInfo":{"status":"ok","timestamp":1756185524764,"user_tz":-420,"elapsed":4734,"user":{"displayName":"Izzul Fahmi","userId":"00788704352414636877"}},"outputId":"fdba9913-d01f-4716-a3ab-76fa6d61c3e0"},"source":["!git clone --depth 1 https://github.com/ggml-org/llama.cpp"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'llama.cpp'...\n","remote: Enumerating objects: 1617, done.\u001b[K\n","remote: Counting objects: 100% (1617/1617), done.\u001b[K\n","remote: Compressing objects: 100% (1252/1252), done.\u001b[K\n","remote: Total 1617 (delta 331), reused 1083 (delta 310), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (1617/1617), 24.05 MiB | 12.69 MiB/s, done.\n","Resolving deltas: 100% (331/331), done.\n","Updating files: 100% (1443/1443), done.\n"]}]},{"cell_type":"code","metadata":{"id":"0693f18e","executionInfo":{"status":"ok","timestamp":1756185524781,"user_tz":-420,"elapsed":10,"user":{"displayName":"Izzul Fahmi","userId":"00788704352414636877"}}},"source":["!cd llama.cpp"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"13e252f8","executionInfo":{"status":"ok","timestamp":1756185637291,"user_tz":-420,"elapsed":112504,"user":{"displayName":"Izzul Fahmi","userId":"00788704352414636877"}},"outputId":"fb26acc2-384d-4c2f-ae5e-3dd000893db3"},"source":["!pip -q install -r llama.cpp/requirements.txt\n","!pip -q install -r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.6/343.6 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.8/402.8 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.6/389.6 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n","diffusers 0.34.0 requires huggingface-hub>=0.27.0, but you have huggingface-hub 0.23.5 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.4.1+cpu which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n","gradio 5.42.0 requires huggingface-hub<1.0,>=0.33.5, but you have huggingface-hub 0.23.5 which is incompatible.\n","datasets 4.0.0 requires huggingface-hub>=0.24.0, but you have huggingface-hub 0.23.5 which is incompatible.\n","peft 0.17.0 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.23.5 which is incompatible.\n","torchvision 0.23.0+cu126 requires torch==2.8.0, but you have torch 2.4.1+cpu which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["%%bash\n","HF_DIR=\"/content/drive/MyDrive/Sorachio-1B-4096-2e-4\"\n","OUT_DIR=\"/content/drive/MyDrive/Sorachio-1B-GGUF\"\n","OUTFILE=\"$OUT_DIR/sorachio-1b-q8_0.gguf\"\n","\n","mkdir -p \"$OUT_DIR\"\n","\n","python3 /content/llama.cpp/convert_hf_to_gguf.py \\\n","  \"$HF_DIR\" \\\n","  --outfile \"$OUTFILE\" \\\n","  --outtype q8_0\n","\n","echo \"✅ GGUF saved to: $OUTFILE\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rYeka3eTUhfR","executionInfo":{"status":"ok","timestamp":1756185690855,"user_tz":-420,"elapsed":53557,"user":{"displayName":"Izzul Fahmi","userId":"00788704352414636877"}},"outputId":"2a798b2f-f60c-4c9d-9f7f-17b6f9eff43b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ GGUF saved to: /content/drive/MyDrive/Sorachio-1B-GGUF/sorachio-1b-q8_0.gguf\n"]},{"output_type":"stream","name":"stderr","text":["INFO:hf-to-gguf:Loading model: Sorachio-1B-4096-2e-4\n","WARNING:hf-to-gguf:Failed to load model config from /content/drive/MyDrive/Sorachio-1B-4096-2e-4: The checkpoint you are trying to load has model type `gemma3_text` but Transformers does not recognize this architecture. This could be because of an issue with the checkpoint, or because your version of Transformers is out of date.\n","WARNING:hf-to-gguf:Trying to load config.json instead\n","INFO:hf-to-gguf:Model architecture: Gemma3ForCausalLM\n","WARNING:hf-to-gguf:Failed to load model config from /content/drive/MyDrive/Sorachio-1B-4096-2e-4: The checkpoint you are trying to load has model type `gemma3_text` but Transformers does not recognize this architecture. This could be because of an issue with the checkpoint, or because your version of Transformers is out of date.\n","WARNING:hf-to-gguf:Trying to load config.json instead\n","INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n","INFO:hf-to-gguf:Exporting model...\n","INFO:hf-to-gguf:gguf: loading model part 'model.safetensors'\n","WARNING:hf-to-gguf:ignore token 262144: id is out of range, max=262143\n","WARNING:hf-to-gguf:ignore token 262144: id is out of range, max=262143\n","INFO:hf-to-gguf:token_embd.weight,                 torch.float16 --> Q8_0, shape = {1152, 262144}\n","INFO:hf-to-gguf:blk.0.attn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.0.ffn_down.weight,             torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.0.ffn_gate.weight,             torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.0.ffn_up.weight,               torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.0.post_attention_norm.weight,  torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.0.post_ffw_norm.weight,        torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.0.ffn_norm.weight,             torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.0.attn_k_norm.weight,          torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.0.attn_k.weight,               torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.0.attn_output.weight,          torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.0.attn_q_norm.weight,          torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.0.attn_q.weight,               torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.0.attn_v.weight,               torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.1.attn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.1.ffn_down.weight,             torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.1.ffn_gate.weight,             torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.1.ffn_up.weight,               torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.1.post_attention_norm.weight,  torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.1.post_ffw_norm.weight,        torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.1.ffn_norm.weight,             torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.1.attn_k_norm.weight,          torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.1.attn_k.weight,               torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.1.attn_output.weight,          torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.1.attn_q_norm.weight,          torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.1.attn_q.weight,               torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.1.attn_v.weight,               torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.10.attn_norm.weight,           torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.10.ffn_down.weight,            torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.10.ffn_gate.weight,            torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.10.ffn_up.weight,              torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.10.post_attention_norm.weight, torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.10.post_ffw_norm.weight,       torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.10.ffn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.10.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.10.attn_k.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.10.attn_output.weight,         torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.10.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.10.attn_q.weight,              torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.10.attn_v.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.11.attn_norm.weight,           torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.11.ffn_down.weight,            torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.11.ffn_gate.weight,            torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.11.ffn_up.weight,              torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.11.post_attention_norm.weight, torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.11.post_ffw_norm.weight,       torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.11.ffn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.11.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.11.attn_k.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.11.attn_output.weight,         torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.11.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.11.attn_q.weight,              torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.11.attn_v.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.12.attn_norm.weight,           torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.12.ffn_down.weight,            torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.12.ffn_gate.weight,            torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.12.ffn_up.weight,              torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.12.post_attention_norm.weight, torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.12.post_ffw_norm.weight,       torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.12.ffn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.12.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.12.attn_k.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.12.attn_output.weight,         torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.12.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.12.attn_q.weight,              torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.12.attn_v.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.13.attn_norm.weight,           torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.13.ffn_down.weight,            torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.13.ffn_gate.weight,            torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.13.ffn_up.weight,              torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.13.post_attention_norm.weight, torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.13.post_ffw_norm.weight,       torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.13.ffn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.13.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.13.attn_k.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.13.attn_output.weight,         torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.13.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.13.attn_q.weight,              torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.13.attn_v.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.14.attn_norm.weight,           torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.14.ffn_down.weight,            torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.14.ffn_gate.weight,            torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.14.ffn_up.weight,              torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.14.post_attention_norm.weight, torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.14.post_ffw_norm.weight,       torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.14.ffn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.14.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.14.attn_k.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.14.attn_output.weight,         torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.14.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.14.attn_q.weight,              torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.14.attn_v.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.15.attn_norm.weight,           torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.15.ffn_down.weight,            torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.15.ffn_gate.weight,            torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.15.ffn_up.weight,              torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.15.post_attention_norm.weight, torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.15.post_ffw_norm.weight,       torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.15.ffn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.15.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.15.attn_k.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.15.attn_output.weight,         torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.15.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.15.attn_q.weight,              torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.15.attn_v.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.16.attn_norm.weight,           torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.16.ffn_down.weight,            torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.16.ffn_gate.weight,            torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.16.ffn_up.weight,              torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.16.post_attention_norm.weight, torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.16.post_ffw_norm.weight,       torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.16.ffn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.16.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.16.attn_k.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.16.attn_output.weight,         torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.16.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.16.attn_q.weight,              torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.16.attn_v.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.17.attn_norm.weight,           torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.17.ffn_down.weight,            torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.17.ffn_gate.weight,            torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.17.ffn_up.weight,              torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.17.post_attention_norm.weight, torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.17.post_ffw_norm.weight,       torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.17.ffn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.17.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.17.attn_k.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.17.attn_output.weight,         torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.17.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.17.attn_q.weight,              torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.17.attn_v.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.18.attn_norm.weight,           torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.18.ffn_down.weight,            torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.18.ffn_gate.weight,            torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.18.ffn_up.weight,              torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.18.post_attention_norm.weight, torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.18.post_ffw_norm.weight,       torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.18.ffn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.18.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.18.attn_k.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.18.attn_output.weight,         torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.18.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.18.attn_q.weight,              torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.18.attn_v.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.19.attn_norm.weight,           torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.19.ffn_down.weight,            torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.19.ffn_gate.weight,            torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.19.ffn_up.weight,              torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.19.post_attention_norm.weight, torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.19.post_ffw_norm.weight,       torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.19.ffn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.19.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.19.attn_k.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.19.attn_output.weight,         torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.19.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.19.attn_q.weight,              torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.19.attn_v.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.2.attn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.2.ffn_down.weight,             torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.2.ffn_gate.weight,             torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.2.ffn_up.weight,               torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.2.post_attention_norm.weight,  torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.2.post_ffw_norm.weight,        torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.2.ffn_norm.weight,             torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.2.attn_k_norm.weight,          torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.2.attn_k.weight,               torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.2.attn_output.weight,          torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.2.attn_q_norm.weight,          torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.2.attn_q.weight,               torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.2.attn_v.weight,               torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.20.attn_norm.weight,           torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.20.ffn_down.weight,            torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.20.ffn_gate.weight,            torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.20.ffn_up.weight,              torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.20.post_attention_norm.weight, torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.20.post_ffw_norm.weight,       torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.20.ffn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.20.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.20.attn_k.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.20.attn_output.weight,         torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.20.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.20.attn_q.weight,              torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.20.attn_v.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.21.attn_norm.weight,           torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.21.ffn_down.weight,            torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.21.ffn_gate.weight,            torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.21.ffn_up.weight,              torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.21.post_attention_norm.weight, torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.21.post_ffw_norm.weight,       torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.21.ffn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.21.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.21.attn_k.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.21.attn_output.weight,         torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.21.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.21.attn_q.weight,              torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.21.attn_v.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.22.attn_norm.weight,           torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.22.ffn_down.weight,            torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.22.ffn_gate.weight,            torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.22.ffn_up.weight,              torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.22.post_attention_norm.weight, torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.22.post_ffw_norm.weight,       torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.22.ffn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.22.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.22.attn_k.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.22.attn_output.weight,         torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.22.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.22.attn_q.weight,              torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.22.attn_v.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.23.attn_norm.weight,           torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.23.ffn_down.weight,            torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.23.ffn_gate.weight,            torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.23.ffn_up.weight,              torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.23.post_attention_norm.weight, torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.23.post_ffw_norm.weight,       torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.23.ffn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.23.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.23.attn_k.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.23.attn_output.weight,         torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.23.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.23.attn_q.weight,              torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.23.attn_v.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.24.attn_norm.weight,           torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.24.ffn_down.weight,            torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.24.ffn_gate.weight,            torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.24.ffn_up.weight,              torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.24.post_attention_norm.weight, torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.24.post_ffw_norm.weight,       torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.24.ffn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.24.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.24.attn_k.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.24.attn_output.weight,         torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.24.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.24.attn_q.weight,              torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.24.attn_v.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.25.attn_norm.weight,           torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.25.ffn_down.weight,            torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.25.ffn_gate.weight,            torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.25.ffn_up.weight,              torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.25.post_attention_norm.weight, torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.25.post_ffw_norm.weight,       torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.25.ffn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.25.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.25.attn_k.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.25.attn_output.weight,         torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.25.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.25.attn_q.weight,              torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.25.attn_v.weight,              torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.3.attn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.3.ffn_down.weight,             torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.3.ffn_gate.weight,             torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.3.ffn_up.weight,               torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.3.post_attention_norm.weight,  torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.3.post_ffw_norm.weight,        torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.3.ffn_norm.weight,             torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.3.attn_k_norm.weight,          torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.3.attn_k.weight,               torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.3.attn_output.weight,          torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.3.attn_q_norm.weight,          torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.3.attn_q.weight,               torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.3.attn_v.weight,               torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.4.attn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.4.ffn_down.weight,             torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.4.ffn_gate.weight,             torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.4.ffn_up.weight,               torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.4.post_attention_norm.weight,  torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.4.post_ffw_norm.weight,        torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.4.ffn_norm.weight,             torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.4.attn_k_norm.weight,          torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.4.attn_k.weight,               torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.4.attn_output.weight,          torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.4.attn_q_norm.weight,          torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.4.attn_q.weight,               torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.4.attn_v.weight,               torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.5.attn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.5.ffn_down.weight,             torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.5.ffn_gate.weight,             torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.5.ffn_up.weight,               torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.5.post_attention_norm.weight,  torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.5.post_ffw_norm.weight,        torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.5.ffn_norm.weight,             torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.5.attn_k_norm.weight,          torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.5.attn_k.weight,               torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.5.attn_output.weight,          torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.5.attn_q_norm.weight,          torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.5.attn_q.weight,               torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.5.attn_v.weight,               torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.6.attn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.6.ffn_down.weight,             torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.6.ffn_gate.weight,             torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.6.ffn_up.weight,               torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.6.post_attention_norm.weight,  torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.6.post_ffw_norm.weight,        torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.6.ffn_norm.weight,             torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.6.attn_k_norm.weight,          torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.6.attn_k.weight,               torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.6.attn_output.weight,          torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.6.attn_q_norm.weight,          torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.6.attn_q.weight,               torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.6.attn_v.weight,               torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.7.attn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.7.ffn_down.weight,             torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.7.ffn_gate.weight,             torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.7.ffn_up.weight,               torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.7.post_attention_norm.weight,  torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.7.post_ffw_norm.weight,        torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.7.ffn_norm.weight,             torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.7.attn_k_norm.weight,          torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.7.attn_k.weight,               torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.7.attn_output.weight,          torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.7.attn_q_norm.weight,          torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.7.attn_q.weight,               torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.7.attn_v.weight,               torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.8.attn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.8.ffn_down.weight,             torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.8.ffn_gate.weight,             torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.8.ffn_up.weight,               torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.8.post_attention_norm.weight,  torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.8.post_ffw_norm.weight,        torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.8.ffn_norm.weight,             torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.8.attn_k_norm.weight,          torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.8.attn_k.weight,               torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.8.attn_output.weight,          torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.8.attn_q_norm.weight,          torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.8.attn_q.weight,               torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.8.attn_v.weight,               torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.9.attn_norm.weight,            torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.9.ffn_down.weight,             torch.float16 --> Q8_0, shape = {6912, 1152}\n","INFO:hf-to-gguf:blk.9.ffn_gate.weight,             torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.9.ffn_up.weight,               torch.float16 --> Q8_0, shape = {1152, 6912}\n","INFO:hf-to-gguf:blk.9.post_attention_norm.weight,  torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.9.post_ffw_norm.weight,        torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.9.ffn_norm.weight,             torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:blk.9.attn_k_norm.weight,          torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.9.attn_k.weight,               torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:blk.9.attn_output.weight,          torch.float16 --> Q8_0, shape = {1024, 1152}\n","INFO:hf-to-gguf:blk.9.attn_q_norm.weight,          torch.float16 --> F32, shape = {256}\n","INFO:hf-to-gguf:blk.9.attn_q.weight,               torch.float16 --> Q8_0, shape = {1152, 1024}\n","INFO:hf-to-gguf:blk.9.attn_v.weight,               torch.float16 --> Q8_0, shape = {1152, 256}\n","INFO:hf-to-gguf:output_norm.weight,                torch.float16 --> F32, shape = {1152}\n","INFO:hf-to-gguf:Set meta model\n","INFO:hf-to-gguf:Set model parameters\n","INFO:hf-to-gguf:Set model quantization version\n","INFO:hf-to-gguf:Set model tokenizer\n","WARNING:hf-to-gguf:ignore token 262144: id is out of range, max=262143\n","WARNING:hf-to-gguf:ignore token 262144: id is out of range, max=262143\n","WARNING:gguf.vocab:Unknown separator token '<bos>' in TemplateProcessing<pair>\n","INFO:gguf.vocab:Setting special token type bos to 2\n","INFO:gguf.vocab:Setting special token type eos to 1\n","INFO:gguf.vocab:Setting special token type unk to 3\n","INFO:gguf.vocab:Setting special token type pad to 1\n","INFO:gguf.vocab:Setting add_bos_token to True\n","INFO:gguf.vocab:Setting add_sep_token to False\n","INFO:gguf.vocab:Setting add_eos_token to False\n","INFO:gguf.vocab:Setting chat_template to {{ bos_token }}\n","{%- if messages[0]['role'] == 'system' -%}\n","    {%- if messages[0]['content'] is string -%}\n","        {%- set first_user_prefix = messages[0]['content'] + '\n","\n","' -%}\n","    {%- else -%}\n","        {%- set first_user_prefix = messages[0]['content'][0]['text'] + '\n","\n","' -%}\n","    {%- endif -%}\n","    {%- set loop_messages = messages[1:] -%}\n","{%- else -%}\n","    {%- set first_user_prefix = \"\" -%}\n","    {%- set loop_messages = messages -%}\n","{%- endif -%}\n","{%- for message in loop_messages -%}\n","    {%- if (message['role'] == 'user') != (loop.index0 % 2 == 0) -%}\n","        {{ raise_exception(\"Conversation roles must alternate user/assistant/user/assistant/...\") }}\n","    {%- endif -%}\n","    {%- if (message['role'] == 'assistant') -%}\n","        {%- set role = \"model\" -%}\n","    {%- else -%}\n","        {%- set role = message['role'] -%}\n","    {%- endif -%}\n","    {{ '<start_of_turn>' + role + '\n","' + (first_user_prefix if loop.first else \"\") }}\n","    {%- if message['content'] is string -%}\n","        {{ message['content'] | trim }}\n","    {%- elif message['content'] is iterable -%}\n","        {%- for item in message['content'] -%}\n","            {%- if item['type'] == 'image' -%}\n","                {{ '<start_of_image>' }}\n","            {%- elif item['type'] == 'text' -%}\n","                {{ item['text'] | trim }}\n","            {%- endif -%}\n","        {%- endfor -%}\n","    {%- else -%}\n","        {{ raise_exception(\"Invalid content type\") }}\n","    {%- endif -%}\n","    {{ '<end_of_turn>\n","' }}\n","{%- endfor -%}\n","{%- if add_generation_prompt -%}\n","    {{'<start_of_turn>model\n","'}}\n","{%- endif -%}\n","\n","INFO:gguf.gguf_writer:Writing the following files:\n","INFO:gguf.gguf_writer:/content/drive/MyDrive/Sorachio-1B-GGUF/sorachio-1b-q8_0.gguf: n_tensors = 340, total_size = 1.1G\n","\rWriting:   0%|          | 0.00/1.06G [00:00<?, ?byte/s]\rWriting:  30%|███       | 321M/1.06G [00:12<00:28, 26.0Mbyte/s]\rWriting:  31%|███       | 329M/1.06G [00:12<00:28, 25.7Mbyte/s]\rWriting:  32%|███▏      | 338M/1.06G [00:13<00:28, 25.8Mbyte/s]\rWriting:  33%|███▎      | 346M/1.06G [00:13<00:28, 25.1Mbyte/s]\rWriting:  33%|███▎      | 349M/1.06G [00:13<00:29, 24.0Mbyte/s]\rWriting:  34%|███▎      | 358M/1.06G [00:14<00:29, 24.1Mbyte/s]\rWriting:  34%|███▍      | 366M/1.06G [00:14<00:31, 22.4Mbyte/s]\rWriting:  35%|███▌      | 375M/1.06G [00:15<00:36, 18.6Mbyte/s]\rWriting:  36%|███▌      | 378M/1.06G [00:15<00:35, 19.1Mbyte/s]\rWriting:  36%|███▋      | 386M/1.06G [00:15<00:31, 21.7Mbyte/s]\rWriting:  37%|███▋      | 395M/1.06G [00:16<00:28, 23.6Mbyte/s]\rWriting:  38%|███▊      | 403M/1.06G [00:16<00:25, 25.6Mbyte/s]\rWriting:  39%|███▉      | 415M/1.06G [00:16<00:21, 30.3Mbyte/s]\rWriting:  40%|███▉      | 423M/1.06G [00:16<00:18, 33.7Mbyte/s]\rWriting:  41%|████      | 432M/1.06G [00:17<00:17, 36.7Mbyte/s]\rWriting:  42%|████▏     | 443M/1.06G [00:17<00:17, 35.9Mbyte/s]\rWriting:  43%|████▎     | 452M/1.06G [00:17<00:15, 38.7Mbyte/s]\rWriting:  43%|████▎     | 460M/1.06G [00:17<00:15, 40.0Mbyte/s]\rWriting:  44%|████▍     | 472M/1.06G [00:17<00:13, 42.7Mbyte/s]\rWriting:  45%|████▌     | 480M/1.06G [00:18<00:13, 44.0Mbyte/s]\rWriting:  46%|████▌     | 489M/1.06G [00:18<00:12, 45.5Mbyte/s]\rWriting:  47%|████▋     | 501M/1.06G [00:18<00:12, 45.4Mbyte/s]\rWriting:  48%|████▊     | 509M/1.06G [00:18<00:14, 39.2Mbyte/s]\rWriting:  49%|████▊     | 517M/1.06G [00:19<00:19, 27.7Mbyte/s]\rWriting:  50%|████▉     | 529M/1.06G [00:19<00:21, 25.2Mbyte/s]\rWriting:  51%|█████     | 538M/1.06G [00:20<00:20, 26.0Mbyte/s]\rWriting:  51%|█████▏    | 546M/1.06G [00:20<00:22, 23.3Mbyte/s]\rWriting:  52%|█████▏    | 549M/1.06G [00:20<00:21, 24.1Mbyte/s]\rWriting:  52%|█████▏    | 558M/1.06G [00:20<00:16, 29.9Mbyte/s]\rWriting:  53%|█████▎    | 566M/1.06G [00:21<00:14, 34.1Mbyte/s]\rWriting:  54%|█████▍    | 575M/1.06G [00:21<00:12, 38.1Mbyte/s]\rWriting:  55%|█████▌    | 586M/1.06G [00:21<00:11, 42.3Mbyte/s]\rWriting:  56%|█████▌    | 595M/1.06G [00:21<00:10, 44.3Mbyte/s]\rWriting:  57%|█████▋    | 603M/1.06G [00:21<00:10, 44.4Mbyte/s]\rWriting:  58%|█████▊    | 615M/1.06G [00:22<00:09, 46.5Mbyte/s]\rWriting:  59%|█████▊    | 623M/1.06G [00:22<00:09, 46.4Mbyte/s]\rWriting:  59%|█████▉    | 632M/1.06G [00:22<00:09, 44.1Mbyte/s]\rWriting:  61%|██████    | 643M/1.06G [00:23<00:13, 32.1Mbyte/s]\rWriting:  61%|██████▏   | 652M/1.06G [00:23<00:14, 27.9Mbyte/s]\rWriting:  62%|██████▏   | 660M/1.06G [00:23<00:17, 23.1Mbyte/s]\rWriting:  62%|██████▏   | 663M/1.06G [00:24<00:18, 22.1Mbyte/s]\rWriting:  63%|██████▎   | 672M/1.06G [00:24<00:17, 22.5Mbyte/s]\rWriting:  64%|██████▍   | 680M/1.06G [00:24<00:14, 27.3Mbyte/s]\rWriting:  65%|██████▍   | 689M/1.06G [00:24<00:11, 31.7Mbyte/s]\rWriting:  66%|██████▌   | 700M/1.06G [00:25<00:10, 35.7Mbyte/s]\rWriting:  67%|██████▋   | 709M/1.06G [00:25<00:09, 38.3Mbyte/s]\rWriting:  67%|██████▋   | 717M/1.06G [00:25<00:08, 40.9Mbyte/s]\rWriting:  69%|██████▊   | 729M/1.06G [00:25<00:07, 43.6Mbyte/s]\rWriting:  69%|██████▉   | 737M/1.06G [00:25<00:07, 45.0Mbyte/s]\rWriting:  70%|███████   | 746M/1.06G [00:26<00:07, 45.0Mbyte/s]\rWriting:  71%|███████▏  | 757M/1.06G [00:26<00:06, 46.9Mbyte/s]\rWriting:  72%|███████▏  | 766M/1.06G [00:26<00:06, 45.2Mbyte/s]\rWriting:  73%|███████▎  | 774M/1.06G [00:26<00:08, 35.3Mbyte/s]\rWriting:  74%|███████▍  | 786M/1.06G [00:28<00:18, 15.3Mbyte/s]\rWriting:  75%|███████▍  | 794M/1.06G [00:29<00:19, 14.1Mbyte/s]\rWriting:  76%|███████▌  | 803M/1.06G [00:29<00:15, 16.8Mbyte/s]\rWriting:  76%|███████▌  | 806M/1.06G [00:29<00:14, 17.8Mbyte/s]\rWriting:  77%|███████▋  | 814M/1.06G [00:29<00:11, 22.0Mbyte/s]\rWriting:  77%|███████▋  | 823M/1.06G [00:29<00:09, 25.3Mbyte/s]\rWriting:  78%|███████▊  | 831M/1.06G [00:30<00:09, 25.6Mbyte/s]\rWriting:  79%|███████▊  | 834M/1.06G [00:30<00:09, 25.1Mbyte/s]\rWriting:  79%|███████▉  | 843M/1.06G [00:30<00:07, 27.7Mbyte/s]\rWriting:  80%|████████  | 851M/1.06G [00:30<00:07, 28.9Mbyte/s]\rWriting:  81%|████████  | 860M/1.06G [00:31<00:06, 29.5Mbyte/s]\rWriting:  81%|████████  | 863M/1.06G [00:31<00:06, 29.1Mbyte/s]\rWriting:  82%|████████▏ | 871M/1.06G [00:31<00:05, 33.3Mbyte/s]\rWriting:  83%|████████▎ | 880M/1.06G [00:31<00:04, 37.7Mbyte/s]\rWriting:  84%|████████▎ | 888M/1.06G [00:31<00:04, 40.9Mbyte/s]\rWriting:  85%|████████▍ | 900M/1.06G [00:32<00:08, 20.2Mbyte/s]\rWriting:  85%|████████▌ | 908M/1.06G [00:33<00:07, 20.0Mbyte/s]\rWriting:  86%|████████▋ | 917M/1.06G [00:34<00:09, 16.2Mbyte/s]\rWriting:  87%|████████▋ | 929M/1.06G [00:34<00:06, 21.5Mbyte/s]\rWriting:  88%|████████▊ | 937M/1.06G [00:34<00:04, 25.3Mbyte/s]\rWriting:  89%|████████▉ | 945M/1.06G [00:34<00:04, 28.9Mbyte/s]\rWriting:  90%|█████████ | 957M/1.06G [00:34<00:03, 34.5Mbyte/s]\rWriting:  91%|█████████ | 966M/1.06G [00:35<00:02, 37.8Mbyte/s]\rWriting:  92%|█████████▏| 974M/1.06G [00:35<00:02, 40.3Mbyte/s]\rWriting:  93%|█████████▎| 986M/1.06G [00:35<00:01, 44.1Mbyte/s]\rWriting:  94%|█████████▎| 994M/1.06G [00:35<00:01, 45.6Mbyte/s]\rWriting:  94%|█████████▍| 1.00G/1.06G [00:35<00:01, 45.5Mbyte/s]\rWriting:  95%|█████████▌| 1.01G/1.06G [00:35<00:01, 47.6Mbyte/s]\rWriting:  96%|█████████▌| 1.02G/1.06G [00:36<00:00, 44.1Mbyte/s]\rWriting:  97%|█████████▋| 1.03G/1.06G [00:36<00:00, 44.8Mbyte/s]\rWriting:  98%|█████████▊| 1.04G/1.06G [00:36<00:00, 46.5Mbyte/s]\rWriting:  99%|█████████▉| 1.05G/1.06G [00:36<00:00, 45.7Mbyte/s]\rWriting: 100%|█████████▉| 1.06G/1.06G [00:37<00:00, 46.9Mbyte/s]\rWriting: 100%|██████████| 1.06G/1.06G [00:37<00:00, 28.6Mbyte/s]\n","INFO:hf-to-gguf:Model successfully exported to /content/drive/MyDrive/Sorachio-1B-GGUF/sorachio-1b-q8_0.gguf\n"]}]}]}